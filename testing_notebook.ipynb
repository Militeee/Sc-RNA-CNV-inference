{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from pyro.optim import Adam\n",
    "import congas as cg\n",
    "from congas.models import MixtureCategorical\n",
    "from pyro.infer import TraceEnum_ELBO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = cg.simulation_data\n",
    "\n",
    "interface = cg.Interface()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data[\"norm_factor\"] = torch.sum(data[\"data\"],axis=0) / 10**3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(15.6250)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((data[\"data\"] / data[\"norm_factor\"]) / 2 )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "interface.set_model(MixtureCategorical)\n",
    "interface.set_optimizer(Adam)\n",
    "interface.set_loss(TraceEnum_ELBO)\n",
    "interface.initialize_model(data)\n",
    "interface.set_model_params({\"lr\" : 0.5,'K': 2, \"nb_size_init\" : torch.ones(32) * 300,\n",
    "                            \"theta_scale\" : torch.ones(32) * 1.5,\n",
    "                            \"theta_rate\" : torch.ones(32) * 0.1,\n",
    "                           \"probs\" : torch.tensor([0.2,0.6,0.2,0.05,0.05])})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MixtureCategorical on 1000 cells wiht 32 segments for 200 steps\n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO: -5833172.480000000  : 100%|██████████| 200/200 [01:29<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "ll = interface.run(steps = 200, MAP = True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing assignment probabilities\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'mixture_weights': array([0.00374981, 0.9962502 ], dtype=float32),\n 'NB_size': array([ 854.645   , 2882.4077  ,  529.0988  , 1248.5513  ,  110.25468 ,\n         739.49176 , 1961.6394  ,    8.88016 ,  667.11163 , 2515.6064  ,\n         661.36774 ,   11.325618, 1024.4348  , 1600.1339  ,  680.1235  ,\n         403.96472 ,  743.3631  ,  395.17523 ,  753.58057 , 1445.3713  ,\n        1531.5133  , 1874.4006  , 2861.2358  ,  112.5937  ,  102.89825 ,\n        1623.1536  , 2252.765   , 1353.7036  ,  404.42322 ,  809.7347  ,\n         127.76866 ,  436.40338 ], dtype=float32),\n 'segment_factor': array([ 9.557074 , 13.469914 ,  8.332872 , 10.2422   ,  6.348126 ,\n         9.4869375, 22.844927 ,  8.474821 ,  9.473433 , 18.80574  ,\n         8.899551 , 14.990898 ,  9.485658 , 11.8296795,  9.740601 ,\n         7.0665975, 10.284135 ,  7.1052775,  9.501918 , 23.009363 ,\n        11.819632 , 13.422286 , 12.627563 ,  6.3217354,  6.2943044,\n        11.823422 , 12.616173 , 10.308484 ,  7.135077 ,  8.684508 ,\n         4.156637 ,  7.123441 ], dtype=float32),\n 'CNV_probabilities': array([[[6.4498552e-11, 5.9548186e-11, 1.0000000e+00, 6.4509745e-11,\n          6.4744446e-11],\n         [6.6326736e-11, 6.5893728e-11, 1.0000000e+00, 6.5671017e-11,\n          6.6233942e-11],\n         [5.7891164e-11, 1.0000000e+00, 6.4391367e-11, 6.4565013e-11,\n          6.4629579e-11],\n         [6.5161203e-11, 6.1530156e-11, 1.0000000e+00, 6.4938242e-11,\n          6.5214542e-11],\n         [2.5689244e-11, 5.2325651e-11, 1.0000000e+00, 5.4486814e-11,\n          5.4486710e-11],\n         [6.4315019e-11, 5.9138000e-11, 1.0000000e+00, 6.4383263e-11,\n          6.4611337e-11],\n         [6.4593594e-11, 6.4433875e-11, 1.0000000e+00, 5.9983414e-11,\n          6.1792661e-11],\n         [4.0168549e-11, 5.6156933e-11, 1.0000000e+00, 5.8825139e-11,\n          5.8793623e-11],\n         [6.4310605e-11, 5.9169815e-11, 1.0000000e+00, 6.4326551e-11,\n          6.4550240e-11],\n         [6.6163110e-11, 6.5870857e-11, 1.0000000e+00, 6.4860999e-11,\n          6.5926035e-11],\n         [6.0085555e-11, 1.0000000e+00, 6.4872260e-11, 6.5076368e-11,\n          6.5141198e-11],\n         [5.2854266e-11, 6.1673743e-11, 1.0000000e+00, 6.2718365e-11,\n          6.3046519e-11],\n         [6.4368282e-11, 5.9305852e-11, 1.0000000e+00, 6.4477028e-11,\n          6.4710987e-11],\n         [6.6045218e-11, 6.4685195e-11, 1.0000000e+00, 6.5472031e-11,\n          6.5915218e-11],\n         [6.4649307e-11, 6.2437396e-11, 5.9920069e-11, 1.0000000e+00,\n          6.4199319e-11],\n         [5.7215510e-11, 5.2413351e-11, 1.0000000e+00, 6.2096543e-11,\n          6.2150576e-11],\n         [6.5179223e-11, 6.1674443e-11, 1.0000000e+00, 6.4879435e-11,\n          6.5184698e-11],\n         [5.7739868e-11, 5.2488385e-11, 1.0000000e+00, 6.2201452e-11,\n          6.2250947e-11],\n         [6.4352565e-11, 5.9222433e-11, 1.0000000e+00, 6.4453297e-11,\n          6.4686680e-11],\n         [6.4253096e-11, 6.4249543e-11, 6.3938785e-11, 1.0000000e+00,\n          5.6511299e-11],\n         [6.5646467e-11, 1.0000000e+00, 6.5858041e-11, 6.6280072e-11,\n          6.6324078e-11],\n         [6.6315099e-11, 6.5863946e-11, 1.0000000e+00, 6.5626567e-11,\n          6.6225858e-11],\n         [6.6247841e-11, 6.5455925e-11, 1.0000000e+00, 6.5693943e-11,\n          6.6150613e-11],\n         [2.6012891e-11, 5.2190693e-11, 1.0000000e+00, 5.4562212e-11,\n          5.4562212e-11],\n         [2.7032571e-11, 5.1999717e-11, 1.0000000e+00, 5.4835140e-11,\n          5.4835140e-11],\n         [6.6041186e-11, 6.4711361e-11, 1.0000000e+00, 6.5445815e-11,\n          6.5927291e-11],\n         [6.6231791e-11, 6.5495387e-11, 1.0000000e+00, 6.5596528e-11,\n          6.6111262e-11],\n         [6.5341788e-11, 6.1832275e-11, 1.0000000e+00, 6.4970952e-11,\n          6.5288469e-11],\n         [5.7681748e-11, 5.2482376e-11, 1.0000000e+00, 6.2196352e-11,\n          6.2248214e-11],\n         [6.3028360e-11, 5.6568455e-11, 1.0000000e+00, 6.3794317e-11,\n          6.3935614e-11],\n         [3.9210364e-11, 1.0000000e+00, 5.9432452e-11, 5.9442881e-11,\n          5.9446510e-11],\n         [5.7493701e-11, 5.2412952e-11, 1.0000000e+00, 6.2144179e-11,\n          6.2202042e-11]],\n \n        [[6.4274183e-11, 5.7153341e-11, 1.0000000e+00, 6.4245623e-11,\n          6.4755187e-11],\n         [6.7536428e-11, 6.6448798e-11, 1.0000000e+00, 6.6518548e-11,\n          6.7374314e-11],\n         [5.5487021e-11, 1.0000000e+00, 6.4142282e-11, 6.4593594e-11,\n          6.4797195e-11],\n         [6.5488268e-11, 5.9797674e-11, 1.0000000e+00, 6.4930936e-11,\n          6.5445191e-11],\n         [8.2931544e-12, 3.6482331e-11, 1.0000000e+00, 4.1176531e-11,\n          4.1176763e-11],\n         [6.4071609e-11, 5.6939967e-11, 1.0000000e+00, 6.4121493e-11,\n          6.4588911e-11],\n         [6.4452069e-11, 6.4176060e-11, 1.0000000e+00, 5.7469800e-11,\n          5.9140477e-11],\n         [5.3318717e-11, 1.0000000e+00, 6.0976384e-11, 5.9956082e-11,\n          6.0500362e-11],\n         [6.3848364e-11, 5.6735509e-11, 1.0000000e+00, 6.3990029e-11,\n          6.4431661e-11],\n         [6.7061232e-11, 6.6563095e-11, 1.0000000e+00, 6.4220018e-11,\n          6.6324710e-11],\n         [5.8082393e-11, 1.0000000e+00, 6.4791263e-11, 6.5284486e-11,\n          6.5514129e-11],\n         [5.7127292e-11, 1.0000000e+00, 5.8540062e-11, 6.0535563e-11,\n          6.3209792e-11],\n         [6.4177164e-11, 5.6967344e-11, 1.0000000e+00, 6.4223328e-11,\n          6.4712714e-11],\n         [6.6955406e-11, 6.4296131e-11, 1.0000000e+00, 6.6069414e-11,\n          6.6795833e-11],\n         [6.4762598e-11, 6.0857638e-11, 5.7940430e-11, 1.0000000e+00,\n          6.3727912e-11],\n         [5.4070325e-11, 4.8745341e-11, 1.0000000e+00, 6.1083590e-11,\n          6.1205228e-11],\n         [6.5262448e-11, 5.9610233e-11, 1.0000000e+00, 6.4827609e-11,\n          6.5389166e-11],\n         [5.3883568e-11, 4.8785153e-11, 1.0000000e+00, 6.1101652e-11,\n          6.1290743e-11],\n         [6.4281906e-11, 5.7087536e-11, 1.0000000e+00, 6.4235332e-11,\n          6.4747284e-11],\n         [6.4049620e-11, 6.4042778e-11, 6.3358985e-11, 1.0000000e+00,\n          5.3802230e-11],\n         [6.6222701e-11, 1.0000000e+00, 6.6808704e-11, 6.7491866e-11,\n          6.7569408e-11],\n         [6.7581267e-11, 6.6591281e-11, 1.0000000e+00, 6.6589886e-11,\n          6.7395131e-11],\n         [6.7424323e-11, 6.5991580e-11, 1.0000000e+00, 6.6405471e-11,\n          6.7178110e-11],\n         [8.9614982e-12, 3.7134320e-11, 1.0000000e+00, 4.2205215e-11,\n          4.2206343e-11],\n         [1.1340156e-11, 3.8652047e-11, 1.0000000e+00, 4.4942817e-11,\n          4.4945131e-11],\n         [6.6992703e-11, 6.4324955e-11, 1.0000000e+00, 6.6031743e-11,\n          6.6768958e-11],\n         [6.7355038e-11, 6.5632826e-11, 1.0000000e+00, 6.6400274e-11,\n          6.7166453e-11],\n         [6.5605542e-11, 6.0010656e-11, 1.0000000e+00, 6.4989292e-11,\n          6.5546124e-11],\n         [5.4132237e-11, 4.8827973e-11, 1.0000000e+00, 6.1117618e-11,\n          6.1293901e-11],\n         [6.1930946e-11, 5.3943003e-11, 1.0000000e+00, 6.3288569e-11,\n          6.3604781e-11],\n         [3.1767273e-11, 1.0000000e+00, 5.7221731e-11, 5.7259943e-11,\n          5.7296650e-11],\n         [5.4357373e-11, 4.8869995e-11, 1.0000000e+00, 6.1150383e-11,\n          6.1242712e-11]]], dtype=float32),\n 'assignment_probs': array([[4.5848457e-04, 2.5791358e-04, 8.4222126e-04, ..., 5.3965015e-04,\n         8.0813537e-04, 2.5360244e-03],\n        [9.9954236e-01, 9.9974066e-01, 9.9916112e-01, ..., 9.9945843e-01,\n         9.9919158e-01, 9.9746263e-01]], dtype=float32)}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lr = interface.learned_parameters()\n",
    "lr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(lr[\"assignment_probs\"], axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 2 3 3 3 3 3 3 3 2 3 3 3 4 3 3 3 3 4 2 3 3 3 3 3 3 3 3 3 2 3]\n",
      "[3 3 2 3 3 3 3 2 3 3 2 2 3 3 4 3 3 3 3 4 2 3 3 3 3 3 3 3 3 3 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(lr[\"CNV_probabilities\"][0], axis = 1) + 1)\n",
    "print(np.argmax(lr[\"CNV_probabilities\"][1], axis = 1) + 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.0000, 2.0000, 1.0000, 2.0000, 2.0000, 2.0000, 2.0000, 1.3000, 2.0000,\n        2.0000, 1.0000, 1.7000, 2.0000, 2.0000, 3.0000, 2.0000, 2.0000, 2.0000,\n        2.0000, 3.0000, 1.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000, 2.0000,\n        2.0000, 2.0000, 2.0000, 1.0000, 2.0000])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"pld\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}